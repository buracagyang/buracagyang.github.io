---
title: AIC和BIC相关知识
toc: true
comments: true
date: 2019-05-29 15:14:58
tags: 
- 技术备忘
- 统计学运用
---

同步于[CSDN](https://blog.csdn.net/buracag_mc);[音尘杂记](https://www.runblog.online/)

前面在回顾[sklearn](https://github.com/scikit-learn/scikit-learn)时，在广义线性模型中看到选择模型时可以采用AIC和BIC准则，特地复习了下统计学基础，简记如下，以抛砖引玉。

<!--more-->

## 1. 模型拟合优度检验

最基础的一个模型拟合优度的检验量就是R square(方程的确定系数)。
已知一组样本观测值 $(X_i, Y_i)$,其中i=1,2,3,...,n得到如下样本回归方程：
$$
\hat{Y_i} = \hat{\beta_0} + \hat{\beta_1}X_i
$$
而Y的第i个观测值与样本均值的离差 $y_i = Y_i - \bar{Y}$，其可以分解为两部分之和：
$$
y_i = Y_i - \bar{Y} = (Y_i - \hat{Y_i}) + (\hat{Y_i} - \bar{Y}) = e_i + \hat{y_i}
$$
其中 $\hat{y_i} = (\hat{Y_i} - \bar{Y})$是样本拟合值与观测值的平均值之差，可认为是由回归直线解释的部分，通常称之为"离差"；

$e_i = (Y_i - \hat{Y_i})$是实际观测值与回归拟合值之差，是回归直线不能解释的部分，通常称之为"残差"。

如果 $Y_i = \hat{Y_i}$,即实际观测值落在样本回归"线"上，则拟合最好。

对于所有样本点，**可以证明**：
$$
\sum{y_i}^2 = \sum{\hat{y_i}^2} + \sum{e_i^2} + 2\sum{\hat{y_i}^2e_i} = \sum{\hat{y_i}^2} + \sum{e_i^2}
$$
记:
$TSS = \sum{y_i^2} = \sum{(Y_i - \bar{Y})^2}$为总体平方和(Total Sum of Squares)
$ESS = \sum{\hat{y_i}^2} = \sum{(\hat{Y_i} - \bar{Y})^2}$为回归平方和(Explained Sum of Squares, **注意有的教材又称之为Regression Sum of Squares**)
$RSS = \sum{e_i^2} = \sum{(Y_i - \hat{Y_i})^2}$为残差平方和(Residual Sum of Squares, **注意有的教材又称之为Error Sum of Squares**)
$$
TSS = ESS + RSS
$$
所以Y的观测值围绕其均值的总离差(total variation)可分解为两部分：一部分来自回归线(ESS)，另一部分则来自与随机误差(RSS)

> 在给定样本中，TSS不变，如果实际观测点离样本回归线越近，则ESS在TSS中占的比重越大，因此定义**拟合优度：回归平方和ESS与TSS的比值。**

记 $R^2 = \frac{ESS}{TSS} = 1 - \frac{RSS}{TSS}$，称 $R^2$为(样本)可决系数/判定系数

对于回归方程来说，$R^2$有以下几个意义：

1. R square可以作为选择不同模型的标准。在拟合数据之前，不能确定数据的确定模型关系，可以对变量的不同数学形式进行拟合，再看R square的大小。
2. 在数据的关系存在非线性可能情况下：
   a) R squared越大不一定拟合越好；
   b) 如何一个模型的R square很小，不一定代表数据之间没有关系，而很有可能是选择的模型不对，或者存在有其他的函数关系。
3. **当自变量个数增加时，尽管有的自变量与的线性关系不显著，其R square也会增大**，对于这种情况需采用Adjusted R squared进行调整。

## 2. 调整R square

由于在模型中增加变量时，$R^2$没有下降，所以存在一种过度拟合模型的内在趋势，即向模型中增加变量固然可以改善数据拟合程度，但这样也会导致预测的方差正大，这时就需要用到调整 $R^2$。
$$
\bar{R_2} = 1 - \frac{n-1}{n-k}(1-R^2)
$$
调整$R^2$用作拟合优度的度量，它能够适当消除在模型中增加变量所导致的自由度损失。

调整 $R^2$对模型扩张时自由度的损失进行了弥补，但又存在一个问题，随着样本容量的增大，这种弥补是否足以保证该准则肯定能让分析者得到正确的模型，所以提出了另外两个拟合度量指标，一个是赤池信息准则(Akaike Information Criterion, AIC)，另一个是施瓦茨或贝叶斯信息准则(Bayesian Information Criterion,BIC)。

## 3. AIC和BIC

$$
AIC(K) = s_y^2(1-R^2)e^{2k/n}
$$

$$
BIC(K) = s_y^2(1-R^2)n^{k/n}
$$

$s_y^2$中没有对自由度进行修正，虽然随着$R^2$的提高，这两个指标都有所改善(下降),但在其他条件不变的情况下，模型规模扩大又会使这两个指标恶化。与$\bar{R^2}$一样，实现同样的拟合程度，这些指标在平均每次观测使用参数个数(K/n)较少时更有效。使用对数通常更方便，多数统计软件报告度量指标是：
$$
AIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{2K}{n}
$$

$$
BIC(K) = ln(\frac{e^{\prime}e}{n}) + \frac{Kln{n}}{n}
$$

<u>**更一般地：**</u>
$$
AIC(K) = 2K - 2ln(L)
$$
其中k是模型参数个数，L为似然函数。从一组可供选择的模型中选择最佳模型时，通常选择AIC最小的模型。

当两个模型之间存在较大差异时，差异主要体现在似然函数项，当似然函数差异不显著时，上市第一项，即模型复杂度则起作用，从而参数个数少的模型是较好的选择。

一般而言，当模型复杂度提高(k增大)时，似然函数L也会增大，从而使AIC变小，但是k过大时，似然函数增速减缓，导致AIC增大，模型过于复杂容易造成过拟合现象。目标是选取AIC最小的模型，AIC不仅要提高模型拟合度(极大似然)，而且引入了惩罚项，使模型参数尽可能少，有助于降低过拟合的可能性。
$$
BIC(K) = Kln{n} - 2ln(L)
$$
其中k是模型参数个数，n为样本数量，L为似然函数。与AIC类似地，引入了模型参数个数作为惩罚项，但是**BIC的惩罚项比AIC的大**，考虑了样本数量，样本数量过多时，可有效防止模型精度过高造成的模型复杂度过高；其中 $kln{n}$惩罚项在维度过大且训练样本数据相对较少的情况下，可以有效避免出现维度灾难现象。