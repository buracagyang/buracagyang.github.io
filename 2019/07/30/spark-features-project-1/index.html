<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>【Spark】特征工程1-Extractors - Hexo</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Hexo"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Hexo"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Spark MLlib中关于特征处理的相关算法，大致分为以下几组：  提取(Extraction)：从“原始”数据中提取特征 转换(Transformation)：缩放，转换或修改特征 选择(Selection)：从较大的一组特征中选择一个子集 局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。  本文介绍第一组： 特征提取"><meta property="og:type" content="blog"><meta property="og:title" content="【Spark】特征工程1-Extractors"><meta property="og:url" content="http://example.com/2019/07/30/spark-features-project-1/"><meta property="og:site_name" content="Hexo"><meta property="og:description" content="Spark MLlib中关于特征处理的相关算法，大致分为以下几组：  提取(Extraction)：从“原始”数据中提取特征 转换(Transformation)：缩放，转换或修改特征 选择(Selection)：从较大的一组特征中选择一个子集 局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。  本文介绍第一组： 特征提取"><meta property="og:locale" content="en_US"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:published_time" content="2019-07-30T10:07:31.000Z"><meta property="article:modified_time" content="2019-08-08T07:37:58.000Z"><meta property="article:author" content="Buracag"><meta property="article:tag" content="技术备忘"><meta property="article:tag" content="大数据"><meta property="twitter:card" content="summary"><meta property="twitter:image:src" content="http://example.com/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2019/07/30/spark-features-project-1/"},"headline":"【Spark】特征工程1-Extractors","image":["http://example.com/img/og_image.png"],"datePublished":"2019-07-30T10:07:31.000Z","dateModified":"2019-08-08T07:37:58.000Z","author":{"@type":"Person","name":"Buracag"},"publisher":{"@type":"Organization","name":"Hexo","logo":{"@type":"ImageObject","url":"http://example.com/img/logo.svg"}},"description":"Spark MLlib中关于特征处理的相关算法，大致分为以下几组：  提取(Extraction)：从“原始”数据中提取特征 转换(Transformation)：缩放，转换或修改特征 选择(Selection)：从较大的一组特征中选择一个子集 局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。  本文介绍第一组： 特征提取"}</script><link rel="canonical" href="http://example.com/2019/07/30/spark-features-project-1/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.0.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }

          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if (!$tabMenu) {
            return;
          }

          const $tabMenuContainer = $tabMenu.parentElement.parentElement;
          Array.from($tabMenuContainer.children).forEach($menu => $menu.classList.remove('is-active'));
          Array.from($tabMenuContainer.querySelectorAll('a'))
              .map($menu => document.getElementById($menu.getAttribute("href").substring(1)))
              .forEach($content => $content.classList.add('is-hidden'));

          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"></head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item is-hidden-tablet catalogue" title="Catalogue" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2019-07-30T10:07:31.000Z" title="2019/7/30 18:07:31">2019-07-30</time></span><span class="level-item">Updated&nbsp;<time dateTime="2019-08-08T07:37:58.000Z" title="2019/8/8 15:37:58">2019-08-08</time></span><span class="level-item">17 minutes read (About 2615 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">【Spark】特征工程1-Extractors</h1><div class="content"><p>Spark MLlib中关于特征处理的相关算法，大致分为以下几组：</p>
<ul>
<li>提取(Extraction)：从“原始”数据中提取特征</li>
<li>转换(Transformation)：缩放，转换或修改特征</li>
<li>选择(Selection)：从较大的一组特征中选择一个子集</li>
<li>局部敏感哈希(Locality Sensitive Hashing，LSH)：这类算法将特征变换的各个方面与其他算法相结合。</li>
</ul>
<p>本文介绍第一组： 特征提取器(Extractors)</p>
<span id="more"></span>
<h1 id="1-特诊提取器"><a href="#1-特诊提取器" class="headerlink" title="1. 特诊提取器"></a>1. 特诊提取器</h1><h2 id="1-1-TF-IDF"><a href="#1-1-TF-IDF" class="headerlink" title="1.1 TF-IDF"></a>1.1 TF-IDF</h2><p>词频-逆文本频率<a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">(Term frequency-inverse document frequency, (TF-IDF)</a>是在文本挖掘中广泛使用的特征向量化方法，以反映术语对语料库中的文档的重要性。 用t表示一个术语，用d表示一个文件，用D表示语料库。词频TF(t，d)是术语t出现在文件d中的次数，而文档频率DF(t，D)是包含术语t的文件数量。 如果我们仅使用词频来衡量重要性，那么过分强调经常出现但很少提供有关文档的信息的术语非常容易，例如： “a”，“the”和“of”。 如果词语在语料库中经常出现，则表示它不包含有关特定文档的特殊信息。 逆向文档频率是词语提供的信息量的数字度量：</p>
<script type="math/tex; mode=display">
IDF(t,D) = log\frac{|D| + 1}{DF(t,D) + 1}</script><p>其中|D|是语料库中的文档总数。 由于使用了对数log，如果一个术语出现在所有文档中，其IDF值将变为0。请注意，应用平滑词语以避免语料库外的术语除以零。 TF-IDF指标只是TF和IDF的产物：</p>
<script type="math/tex; mode=display">
TF-IDF = TF(t,d) \times IDF(t,D)</script><p>词频和文档频率的定义有几种变体。 在MLlib中，我们将TF和IDF分开以使其灵活。</p>
<p><strong>TF</strong>：HashingTF和CountVectorizer都可用于生成术语频率向量。</p>
<ol>
<li>HashingTF是一个Transformer，它接受一组词语并将这些集合转换为固定长度的特征向量。在文本处理中，“一组词语”可能是一个单词集合。 HashingTF利用散列技巧。通过应用散列函数将原始特征映射到索引。这里使用的哈希函数是<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/MurmurHash">MurmurHash 3</a>.然后，基于映射的索引计算术语频率。这种方法避免了计算全局词语到索引映射的需要，这对于大型语料库来说可能是昂贵的，但它遭受潜在的哈希冲突，其中不同的原始特征可能在散列之后变成相同的词语。为了减少冲突的可能性，我们可以增加目标特征维度，即哈希表的桶的数量。由于散列值的简单模数用于确定向量索引，因此建议使用2的幂作为要素维度，否则要素将不会均匀映射到向量索引。默认要素尺寸为$2^{18} = 262,144$。可选的二进制切换参数控制术语频率计数。设置为true时，所有非零频率计数都设置为1.这对于模拟二进制而非整数计数的离散概率模型特别有用。</li>
<li>CountVectorizer将文本文档转换为词语计数向量。</li>
</ol>
<p><strong>IDF</strong>：IDF是一个Estimator，它训练数据集并生成IDFModel。 IDFModel采用特征向量（通常从HashingTF或CountVectorizer创建）并缩放每个特征。 直观地，它降低了在语料库中频繁出现的特征。</p>
<p><strong>举例</strong></p>
<p>在下面的代码中(基于Python)，Scala和Java的示例还请参照<a target="_blank" rel="noopener" href="http://spark.apache.org/docs/2.3.2/ml-features.html#bucketizer">这里</a>；我们从一组句子开始。 我们使用Tokenizer将每个句子分成单词。 对于每个句子，我们使用HashingTF将句子散列为特征向量。 我们使用IDF重新缩放特征向量; 这通常会在使用文本作为功能时提高性能。 然后我们的特征向量可以传递给学习算法。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:03</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : tf_idf_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> HashingTF, IDF, Tokenizer</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">&quot;TfIdfExample&quot;</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    sentenceData = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0.0</span>, <span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">        (<span class="number">0.0</span>, <span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">        (<span class="number">1.0</span>, <span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">    ], [<span class="string">&quot;label&quot;</span>, <span class="string">&quot;sentence&quot;</span>])</span><br><span class="line"></span><br><span class="line">    tokenizer = Tokenizer(inputCol=<span class="string">&quot;sentence&quot;</span>, outputCol=<span class="string">&quot;words&quot;</span>)</span><br><span class="line">    wordsData = tokenizer.transform(sentenceData)</span><br><span class="line"></span><br><span class="line">    hashingTF = HashingTF(inputCol=<span class="string">&quot;words&quot;</span>, outputCol=<span class="string">&quot;rawFeatures&quot;</span>, numFeatures=<span class="number">20</span>)</span><br><span class="line">    featurizedData = hashingTF.transform(wordsData)</span><br><span class="line">    <span class="comment"># 也可以选择CountVectorizer得到一个词频向量</span></span><br><span class="line"></span><br><span class="line">    idf = IDF(inputCol=<span class="string">&quot;rawFeatures&quot;</span>, outputCol=<span class="string">&quot;features&quot;</span>)</span><br><span class="line">    idfModel = idf.fit(featurizedData)</span><br><span class="line">    rescaledData = idfModel.transform(featurizedData)</span><br><span class="line"></span><br><span class="line">    rescaledData.select(<span class="string">&quot;label&quot;</span>, <span class="string">&quot;features&quot;</span>).show()</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">+-----+--------------------+</span><br><span class="line">|label|            features|</span><br><span class="line">+-----+--------------------+</span><br><span class="line">|  0.0|(20,[0,5,9,17],[0...|</span><br><span class="line">|  0.0|(20,[2,7,9,13,15]...|</span><br><span class="line">|  1.0|(20,[4,6,13,15,18...|</span><br><span class="line">+-----+--------------------+</span><br></pre></td></tr></table></figure>
<h2 id="1-2-Word2Vec"><a href="#1-2-Word2Vec" class="headerlink" title="1.2 Word2Vec"></a>1.2 Word2Vec</h2><p>Word2Vec是一个Estimator，它采用代表文档的单词序列并训练Word2VecModel。 该模型将每个单词映射到一个<strong>唯一的固定大小的向量</strong>。 Word2VecModel使用文档中所有单词的平均值将每个文档转换为向量; 然后，此向量可用作预测，文档相似度计算等功能。</p>
<p><strong>举例</strong></p>
<p>我们从一组文档开始，每个文档都表示为一系列单词。 对于每个文档，我们将其转换为特征向量。 然后可以将该特征向量传递给学习算法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:09</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : word2vec_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> Word2Vec</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">&quot;Word2VecExample&quot;</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输入数据: 每行是一个句子或文档中的单词集合。</span></span><br><span class="line">    documentDF = spark.createDataFrame([</span><br><span class="line">        (<span class="string">&quot;Hi I heard about Spark&quot;</span>.split(<span class="string">&quot; &quot;</span>), ),</span><br><span class="line">        (<span class="string">&quot;I wish Java could use case classes&quot;</span>.split(<span class="string">&quot; &quot;</span>), ),</span><br><span class="line">        (<span class="string">&quot;Logistic regression models are neat&quot;</span>.split(<span class="string">&quot; &quot;</span>), )</span><br><span class="line">    ], [<span class="string">&quot;text&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 从单词到向量的映射。</span></span><br><span class="line">    word2Vec = Word2Vec(vectorSize=<span class="number">3</span>, minCount=<span class="number">0</span>, inputCol=<span class="string">&quot;text&quot;</span>, outputCol=<span class="string">&quot;result&quot;</span>)</span><br><span class="line">    model = word2Vec.fit(documentDF)</span><br><span class="line"></span><br><span class="line">    result = model.transform(documentDF)</span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> result.collect():</span><br><span class="line">        text, vector = row</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Text: [%s] =&gt; \nVector: %s\n&quot;</span> % (<span class="string">&quot;, &quot;</span>.join(text), <span class="built_in">str</span>(vector)))</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Text: [Hi, I, heard, about, Spark] =&gt; </span><br><span class="line">Vector: [0.010823638737201692,-0.005407899245619774,-0.02091031074523926]</span><br><span class="line"></span><br><span class="line">Text: [I, wish, Java, could, use, <span class="keyword">case</span>, classes] =&gt; </span><br><span class="line">Vector: [0.04387364802615983,0.028466253940548213,-0.02133789997813957]</span><br><span class="line"></span><br><span class="line">Text: [Logistic, regression, models, are, neat] =&gt; </span><br><span class="line">Vector: [0.054717136174440385,0.009467959217727185,0.034012694098055365]</span><br></pre></td></tr></table></figure>
<h2 id="1-3-CountVectorizer"><a href="#1-3-CountVectorizer" class="headerlink" title="1.3 CountVectorizer"></a>1.3 CountVectorizer</h2><p>CountVectorizer和CountVectorizerModel旨在帮助将文本文档集合转换为计数向量(vectors of token counts)。当a-priori字典不可用时，CountVectorizer可用作Estimator来提取词汇表，并生成CountVectorizerModel。该模型为词汇表上的文档生成稀疏表示，然后可以将其传递给其他算法，如LDA。</p>
<p>在拟合过程中，CountVectorizer将选择按语料库中的术语频率排序的顶级词汇量词。可选参数minDF还通过指定词语必须出现在文档中的最小数量（或&lt;1.0）来影响拟合过程。另一个可选的二进制切换参数控制输出向量。如果设置为true，则所有非零计数都设置为1.这对于模拟二进制而非整数计数的离散概率模型尤其有用。</p>
<p><strong>举例</strong></p>
<p>假设我们有以下DataFrame，其中包含列id和文本：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="built_in">id</span> | texts</span><br><span class="line">----|----------</span><br><span class="line"> 0  | Array(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line"> 1  | Array(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;a&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>文本中的每一行都是Array [String]类型的文档。 调用CountVectorizer的拟合会生成带有词汇表（a，b，c）的CountVectorizerModel。 然后转换后的输出列“vector”包含：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="built_in">id</span> | texts                           | vector</span><br><span class="line">----|---------------------------------|---------------</span><br><span class="line"> 0  | Array(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>)            | (3,[0,1,2],[1.0,1.0,1.0])</span><br><span class="line"> 1  | Array(<span class="string">&quot;a&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;b&quot;</span>, <span class="string">&quot;c&quot;</span>, <span class="string">&quot;a&quot;</span>)  | (3,[0,1,2],[2.0,2.0,1.0])</span><br></pre></td></tr></table></figure>
<p>每个向量表示文档在词汇表中的词语计数(id 0: ‘a’, ‘b’, ‘c’各出现一次；id1: ‘a’, ‘b’, ‘c’各出现2， 2， 1次)。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:24</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : count_vectorizer_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">&quot;CountVectorizerExample&quot;</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    df = spark.createDataFrame([</span><br><span class="line">        (<span class="number">0</span>, <span class="string">&quot;a b c&quot;</span>.split(<span class="string">&quot; &quot;</span>)),</span><br><span class="line">        (<span class="number">1</span>, <span class="string">&quot;a b b c a&quot;</span>.split(<span class="string">&quot; &quot;</span>))</span><br><span class="line">    ], [<span class="string">&quot;id&quot;</span>, <span class="string">&quot;words&quot;</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 用语料库拟合一个CountVectorizerModel</span></span><br><span class="line">    cv = CountVectorizer(inputCol=<span class="string">&quot;words&quot;</span>, outputCol=<span class="string">&quot;features&quot;</span>, vocabSize=<span class="number">3</span>, minDF=<span class="number">2.0</span>)</span><br><span class="line"></span><br><span class="line">    model = cv.fit(df)</span><br><span class="line">    result = model.transform(df)</span><br><span class="line">    result.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|<span class="built_in">id</span> |words          |features                 |</span><br><span class="line">+---+---------------+-------------------------+</span><br><span class="line">|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|</span><br><span class="line">|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|</span><br><span class="line">+---+---------------+-------------------------+</span><br></pre></td></tr></table></figure>
<h2 id="1-4-FeatureHasher"><a href="#1-4-FeatureHasher" class="headerlink" title="1.4 FeatureHasher"></a>1.4 FeatureHasher</h2><p>特征散列(Feature Hashing)将一组分类或数字特征映射到指定尺寸的特征向量中（通常远小于原始特征空间的特征向量）。这是使用散列技巧将要素映射到特征向量中的索引来完成的。</p>
<p>FeatureHasher转换器在多个特征上运行。每个特征可能是数值特征或分类特征。不同数据类型的处理方法如下：</p>
<ul>
<li>数值特征：对于数值特征，特征名称的哈希值用于将值映射到向量中的索引。默认情况下，数值元素不被视为分类属性（即使它们是整数）。要将它们视为分类属性，请使用categoricalCols参数指定相关列。</li>
<li>字符串(属性)特征：对于属性特征，字符串“column_name = value”的哈希值用于映射到矢量索引，指示符值为1.0。因此，属性特征是“one-hot”编码的（类似于使用具有dropLast = false的OneHotEncoder）。</li>
<li>布尔特征：布尔值的处理方式与字符串特征相同。也就是说，布尔特征表示为“column_name = true”或“column_name = false”，指标值为1.0。</li>
</ul>
<p>忽略空（缺失）值（在结果特征向量中隐式为零）。</p>
<p>这里使用的哈希函数也是HashingTF中使用的MurmurHash 3。由于散列值的简单模数用于确定向量索引，因此建议使用2的幂作为numFeatures参数;否则，特征将不会均匀地映射到矢量索引。</p>
<p><strong>举例</strong></p>
<p>假设我们有一个DataFrame，其中包含4个输入列real，bool，stringNum和string。这些不同的数据类型作为输入将说明变换的行为以产生一列特征向量。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">real| bool|stringNum|string</span><br><span class="line">----|-----|---------|------</span><br><span class="line"> 2.2| <span class="literal">true</span>|        1|   foo</span><br><span class="line"> 3.3|<span class="literal">false</span>|        2|   bar</span><br><span class="line"> 4.4|<span class="literal">false</span>|        3|   baz</span><br><span class="line"> 5.5|<span class="literal">false</span>|        4|   foo</span><br></pre></td></tr></table></figure>
<p>训练过程示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time     : 2019/7/31 14:34</span></span><br><span class="line"><span class="comment"># @Author   : buracagyang</span></span><br><span class="line"><span class="comment"># @File     : feature_hasher_example.py</span></span><br><span class="line"><span class="comment"># @Software : PyCharm</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Describe:</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> SparkSession</span><br><span class="line"><span class="keyword">from</span> pyspark.ml.feature <span class="keyword">import</span> FeatureHasher</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    spark = SparkSession\</span><br><span class="line">        .builder\</span><br><span class="line">        .appName(<span class="string">&quot;FeatureHasherExample&quot;</span>)\</span><br><span class="line">        .getOrCreate()</span><br><span class="line"></span><br><span class="line">    dataset = spark.createDataFrame([</span><br><span class="line">        (<span class="number">2.2</span>, <span class="literal">True</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;foo&quot;</span>),</span><br><span class="line">        (<span class="number">3.3</span>, <span class="literal">False</span>, <span class="string">&quot;2&quot;</span>, <span class="string">&quot;bar&quot;</span>),</span><br><span class="line">        (<span class="number">4.4</span>, <span class="literal">False</span>, <span class="string">&quot;3&quot;</span>, <span class="string">&quot;baz&quot;</span>),</span><br><span class="line">        (<span class="number">5.5</span>, <span class="literal">False</span>, <span class="string">&quot;4&quot;</span>, <span class="string">&quot;foo&quot;</span>)</span><br><span class="line">    ], [<span class="string">&quot;real&quot;</span>, <span class="string">&quot;bool&quot;</span>, <span class="string">&quot;stringNum&quot;</span>, <span class="string">&quot;string&quot;</span>])</span><br><span class="line"></span><br><span class="line">    hasher = FeatureHasher(inputCols=[<span class="string">&quot;real&quot;</span>, <span class="string">&quot;bool&quot;</span>, <span class="string">&quot;stringNum&quot;</span>, <span class="string">&quot;string&quot;</span>],</span><br><span class="line">                           outputCol=<span class="string">&quot;features&quot;</span>)</span><br><span class="line"></span><br><span class="line">    featurized = hasher.transform(dataset)</span><br><span class="line">    featurized.show(truncate=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    spark.stop()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br><span class="line">|real|bool |stringNum|string|features                                                |</span><br><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br><span class="line">|2.2 |<span class="literal">true</span> |1        |foo   |(262144,[174475,247670,257907,262126],[2.2,1.0,1.0,1.0])|</span><br><span class="line">|3.3 |<span class="literal">false</span>|2        |bar   |(262144,[70644,89673,173866,174475],[1.0,1.0,1.0,3.3])  |</span><br><span class="line">|4.4 |<span class="literal">false</span>|3        |baz   |(262144,[22406,70644,174475,187923],[1.0,1.0,4.4,1.0])  |</span><br><span class="line">|5.5 |<span class="literal">false</span>|4        |foo   |(262144,[70644,101499,174475,257907],[1.0,1.0,5.5,1.0]) |</span><br><span class="line">+----+-----+---------+------+--------------------------------------------------------+</span><br></pre></td></tr></table></figure>
<p>然后可以将得到的特征向量传递给学习算法。</p>
</div><div class="article-licensing box"><div class="licensing-title"><p>【Spark】特征工程1-Extractors</p><p><a href="http://example.com/2019/07/30/spark-features-project-1/">http://example.com/2019/07/30/spark-features-project-1/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Buracag</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2019-07-30</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2019-08-08</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E6%8A%80%E6%9C%AF%E5%A4%87%E5%BF%98/">技术备忘</a><a class="link-muted mr-2" rel="tag" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">Like this article? Support the author with</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>Alipay</span><span class="qrcode"><img src="/" alt="Alipay"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>Wechat</span><span class="qrcode"><img src="/" alt="Wechat"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2019/07/31/spark-features-project-2/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">【Spark】特征工程2-Transformers</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/07/30/spark-ml-pipelines/"><span class="level-item">【Spark】Pipelines</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "35e46ca66de9c57a00a4e2d019ffea70",
            repo: "blog_comments",
            owner: "buracagyang",
            clientID: "b59e8ee91a1328df0e4b",
            clientSecret: "e8a8251bb9bd5ec9913a699734a6824bea1d6ec3",
            admin: "buracagyang",
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 20,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><!--!--><div class="column column-right is-4-tablet is-4-desktop is-4-widescreen  order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">Catalogue</h3><ul class="menu-list"><li><a class="level is-mobile" href="#1-特诊提取器"><span class="level-left"><span class="level-item">1. 特诊提取器</span></span></a><ul class="menu-list"><li><a class="level is-mobile" href="#1-1-TF-IDF"><span class="level-left"><span class="level-item">1.1 TF-IDF</span></span></a></li><li><a class="level is-mobile" href="#1-2-Word2Vec"><span class="level-left"><span class="level-item">1.2 Word2Vec</span></span></a></li><li><a class="level is-mobile" href="#1-3-CountVectorizer"><span class="level-left"><span class="level-item">1.3 CountVectorizer</span></span></a></li><li><a class="level is-mobile" href="#1-4-FeatureHasher"><span class="level-left"><span class="level-item">1.4 FeatureHasher</span></span></a></li></ul></li></ul></div></div><style>#toc .menu-list > li > a.is-active + .menu-list { display: block; }#toc .menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="Hexo" height="28"></a><p class="is-size-7"><span>&copy; 2022 Buracag</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>